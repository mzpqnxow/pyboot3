#!/usr/bin/env python3
"""
Build a Python virtual environment without setuptools, virtualenv and
other dependencies. Useful when building on "fresh" systems or those
which for some reason do not have the required dependencies available

This will do all sorts of useful things like make semi-broken Python
distributions work, set the correct build-flags for machines with CPU
architectures that require native code extensions to be built from
source, handle quirky "features" (like the proxy settings in pip.ini
not carrying over to easy_install) and so on. It's meant to "just work"
even in very odd scenarios- typically big-iron/bare-metal hardware and
commercial UNIXes like AIX, Solaris, HP-UX, etc. It also helps on Linux
for POWER

Support Python3 only
No more Python2 support

See Makefile and/or README.md for usage information

Copyright (C) 2018
    Adam Greene <copyright@mzpqnxow.com>
    David Marker <dave@freedave.net>

Please see COPYING for terms
"""
import json
import multiprocessing
import platform
import pwd
import re
import shutil
import subprocess
import sys
from configparser import (ConfigParser, NoOptionError, NoSectionError)
from contextlib import contextmanager
from datetime import datetime
from errno import (ENOENT, ENOTEMPTY)
from os import (
    chdir,
    environ,
    getcwd,
    getuid,
    unlink
)
import os
from os.path import (
    abspath,
    basename,
    dirname,
    exists,
    expanduser,
    expandvars,
    join as join_path, realpath, isdir)
from time import sleep


DEBUG = os.getenv('PYBOOT_DEBUG', False)
RUNNING_PYTHON_VERSION = sys.version_info[0]
assert RUNNING_PYTHON_VERSION == 3
CURDIR = CWD = dirname(abspath(__file__))
# Basic required directories for a virtualenv
VENV_DIRS = {'lib', 'bin', 'include'}
PIP_CONF = 'pip.conf'
BUILD_CONF = 'pyboot-{cpu_arch}-build.ini'
# Taken from etc/
INI_FILES = {'.interactive', PIP_CONF}
# Put your dependencies in these files in your empty venv directory
PKG_REQUIREMENT_FILEPATHS = {'requirements.txt'}
PKG_CONSTRAINT_FILEPATHS = {'constraints.txt'}
# Override this with `make dev PYTHON3=/path/to/python3.x
DEFAULT_VENV_BASE_PYTHON = shutil.which('python3')
CPU_COUNT = multiprocessing.cpu_count()
PYVERSION = 3


def log(msg):
    sys.stderr.write(msg + '\n')


def debug(msg, obj=None):
    """Debug output"""
    if DEBUG is not False:
        sys.stderr.write('[PYBOOT DEBUG] %s' % msg)
        if obj is not None:
            lines = json.dumps(obj, indent=2).splitlines()
            for line in lines:
                sys.stderr.write('[PYBOOT DEBUG] %s' % line)


def get_pyversion_from_name(app):
    """Added for edge cases"""
    version_pattern = '^(?P<full>python(?P<short>\d(?:(?:\.\d)*)))'
    app_path = shutil.which(app)
    app_realpath = realpath(app_path)
    app_realname = basename(app_realpath)
    m = re.match(version_pattern, app_realname)
    return list(m.groups())


def build_flags():
    """Load pyboot-<cpu_arch>-build.ini if it exists to set environment vars

    This feature was added as a hack to set environment variables for building
    native-code packages. The most ubiquitous is OpenSSL, needed for the cryptography
    package. Modern versions require OpenSSL 1.1.1 and our ppc64le system has 1.0.1

    With this, including pyboot-ppc64le-build.ini in the repository will ensure that
    the flags get set

    If there is no pyboot-<cpu_arch>-build.ini present in the root of the repo, this
    function will be a no-op
    """
    build_env = dict()
    allowed_build_vars = ('CFLAGS', 'CPPFLAGS', 'LDFLAGS', 'LD_LIBRARY_PATH')
    cpu_arch = platform.processor()
    if not cpu_arch:
        cpu_arch = platform.machine()
    build_conf = join_path('..', BUILD_CONF.format(cpu_arch=cpu_arch))
    if not cpu_arch:
        raise RuntimeError('Unable to determine CPU architecture!')

    if not exists(build_conf):
        return build_env

    config = ConfigParser()
    config.read(build_conf)

    try:
        section = config['environment']
    except NoSectionError:
        return build_env

    for k, v in section.items():
        k = k.upper()
        if k not in allowed_build_vars:
            continue
        build_env[k.upper()] = v

    return build_env


def get_pip_ini_value(section, key, expand=False):
    config = ConfigParser()
    config.read(PIP_CONF)
    try:
        value = config.get(section, key)
        if expand is True:
            return realpath(expanduser(expandvars(value)))
        return value
    except (NoSectionError, NoOptionError):
        return None


def prep_pip_wheelhouse(create=True):
    """Ensure the pip wheelhouse directory exists; create it if necessary"""
    wheelhouse_dir = get_pip_ini_value('wheel', 'wheel-dir', expand=True)
    if wheelhouse_dir is None:
        return None
    if isdir(wheelhouse_dir):
        # Already exists, nothing to do
        return wheelhouse_dir
    if create is False:
        return None
    print('NOTE: pyboot3 auto-creating wheelhouse directory %s' % wheelhouse_dir)
    mkdir_p(wheelhouse_dir)
    return wheelhouse_dir


def check_and_prep_pip_conf():
    pip_wheelhouse = prep_pip_wheelhouse(create=True)
    find_links_dir = get_pip_ini_value('global', 'find-links', expand=True)
    if pip_wheelhouse != find_links_dir:
        raise RuntimeError('The global.find-links and wheel.wheel-dir values should be the same!')
    return True


def pip_proxy():
    """Parse pip.conf to get proxy settings to pass on to easy_install

    This is a little bit controversial because we make some decisions
    without the consent of the user.  We very intentionally honor
    pip.ini proxy settings as well as proxy settings in the environment.

    The reason for honoring pip.ini proxy settings (manually) is to work
    around a somewhat rare (but not theoretical) bug where easy_install is
    invoked during pip. If pip has a proxy set in pip.ini, it does
    not get honored by easy_install, causing dependency fetches to
    fail in environments with hard requirements for a proxy

    To reproduce failure, set your proxy in pip.ini in an environment
    where a proxy is *REQUIRED* and try to pip install pandas. It will
    bomb out, saying it can't get numpy.

    Rather than making the user specify the proxy in pip.ini AND in the
    environment, we read pip.ini and set it in the environment for
    easy_install to consume.

    This approach fixes that. Hopefully it is now no longer an issue
    """
    return get_pip_ini_value('global', 'proxy')


def find_libpython(python_exe_path):
    """For machines with multiple versions of Python, if LD_LIBRARY_PATH isn't set correctly, we need this

    Example: Our prod server has /opt/Python-3.8 but does not have a proper entry in /etc/ld.so.d/
    To fix this: We add /opt/Python-3.8/lib to LD_LIBRARY_PATH

    The correct fix is on the system owner or the user to set LD_LIBRARY_PATH themselves, though
    """
    try:
        python_root_path = dirname(dirname(realpath(python_exe_path)))
        return join_path(python_root_path, 'lib')
    except:  # noqa
        log('Unable to find libpython, hopefully it is already in your loader search path')
        return None


def update_ld_library_path(env):
    ld_library_path = env.get('LD_LIBRARY_PATH', '')
    libpython_path = find_libpython(DEFAULT_VENV_BASE_PYTHON)
    if libpython_path is not None:
        ':'.join((ld_library_path, libpython_path))
    env['LD_LIBRARY_PATH'] = ld_library_path
    return env


def basic_env(cwd, parallel=True, easy_install_proxy=True):
    """Provide a clean environment with bare essentials"""
    global PYVERSION
    build_flags()
    pent = pwd.getpwuid(getuid())
    env = dict()
    env['PYTHONPATH'] = '{}/packages/lib/python{}/site-packages/'.format(
        cwd, PYVERSION)
    env['HOME'] = pent.pw_dir
    env['SHELL'] = pent.pw_shell
    env['LOGNAME'] = pent.pw_name
    env['PWD'] = getcwd()
    # One can hope that these environment variables make it to a compiled
    # native code build that uses GNU make. Pretty unlikely to work, and
    # even less likely to occur, but doesn't hurt. Maybe cython or pandas
    # or some such thing can benefit.. well, not pandas/cython, yet,
    # but maybe some day. Pandas currently takes 7 minutes to build from
    # source on "unsupported" platforms, but can not at this time benefit
    # from parallelism
    #
    # https://github.com/pandas-dev/pandas/issues/24344
    #
    if parallel is True:
        parallelism_count = '{}'.format(CPU_COUNT if CPU_COUNT == 1 else (CPU_COUNT - 1))
        env['MAKEFLAGS'] = '-j{}'.format(parallelism_count)
        env['CONCURRENCY_LEVEL'] = parallelism_count

    # If pip.ini/pip.conf has a wheelhouse/wheel cache path set, make
    # sure it exists; if it doesn't create it
    check_and_prep_pip_conf()

    if easy_install_proxy is True:
        # For edge cases where pip invokes easy_install and proxy is only
        # set in pip.ini, not in the environment
        proxy = pip_proxy()
        #  NOTE(AG): To be clear: This overrides the environment with what
        #            is set in pip config. This is/was required for easy_setup
        #            which does not honor pip config but still may need to us
        #            HTTP to access the Internet or somewhere else via proxy
        if proxy:  # Note: this overrides the environment with pip config
            environ['http_proxy'] = proxy
            environ['https_proxy'] = proxy

    for key in ('PATH', 'TERM', 'MAIL', 'http_proxy', 'https_proxy', 'CFLAGS', 'LD_LIBRARY_PATH', 'LDFLAGS', 'CPPFLAGS'):
        if key in environ:
            env[key] = environ[key]

    env = update_ld_library_path(env)

    return env


@contextmanager
def pushd(directory):
    """Emulate Bash pushd/popd"""
    cwd = getcwd()
    try:
        chdir(directory)
    except OSError as err:
        if err.errno == ENOENT:
            raise RuntimeError('%s does not exist !!' % directory)
        else:
            raise err
    yield
    chdir(cwd)


def destroy(explain, vdirs, cfg):
    """ Destroy a previously created virtual environment """
    log('%s: destroying %s' % (explain, ('/ '.join(vdirs) + os.path.sep)))
    # rmtree can fail if you work SSHFS/NFS/CIFS/SMB due to locking issues
    retry = 10  # Give it 10 tries, then quit
    done = False
    while retry > 0 and not done:
        retry, done = (retry - 1, True)
        for directory in vdirs:
            try:
                shutil.rmtree(directory)
            except OSError as err:
                if err.errno == ENOENT:
                    pass  # directory already gone
                elif err.errno == ENOTEMPTY:
                    done = False  # try again if retry isn't exhausted.
                else:
                    raise err  # re-raise something is wrong.
        if not done:
            # SSHFS/NFS/CIFS/SMB or some other filesystem locking issue
            sleep(2)

    log('%s: destroying %s' % (explain, (' '.join(cfg))))
    for cfgfile in cfg:
        try:
            unlink(cfgfile)
        except (IOError, OSError):
            pass


def invoke_virtualenv(virtualenv_exe, python, pipini, interactive, cwd, new_venv=True):
    """ Run virtualenv with the arguments and environment set """
    shutil.copy(pipini, 'pip.conf')
    shutil.copy(interactive, '.interactive')

    try:
        clear_app_data = '--reset-app-data' if new_venv is True else '--clear-app-data'
        # subprocess.check_call([python, virtualenv_exe, clear_app_data, '-p', python, '.'], env=basic_env(cwd))
        # This may be more reliable in some cases ...
        subprocess.check_call([python, '-mvirtualenv', clear_app_data, '-p', python, '.'], env=basic_env(cwd))
    except OSError as err:
        if err.errno == ENOENT:
            raise RuntimeError('Python %s does not exist !!' % python)
        else:
            raise err


def freeze(*args, **kwargs):
    pip(*args, **kwargs)


def install(*args, **kwargs):
    pip(*args, **kwargs)


def mkdir_p(*args) -> None:
    """emulate mkdir -p behavior, treat args like os.path.join"""
    return os.makedirs(expanduser(expandvars(join_path(*args))), exist_ok=True)


def find_first_file(file_list, default_file='/dev/null', file_fn=exists):
    for file in file_list:
        if file_fn(file):
            return file
    else:
        return default_file


def merge_build_ini_environment(env):
    build_env = build_flags()

    for k, v in build_env.items():
        if not k.endswith('PATH'):
            env[k] = v
            continue
        # For things like LD_LIBRARY_PATH, PATH, etc. we don't want to completely
        # overwrite the path value, we want to add to it, hence this bit of logic
        current_env_value = env.get(k, '')
        env[k] = ':'.join((current_env_value, v))
        env[k] = ':'.join(filter(None, env[k].split(':')))

    return env


def pip(pip_exe, ini, require, constrain, cwd, prerelease=False, action='install', parallel=True, easy_install_proxy=True):
    """
        Set 'PIP_CONFIG_FILE' environment variable to ini, then call
        exe as pip using the require file.
    """
    environ['PIP_CONFIG_FILE'] = ini

    req = find_first_file(require, default_file=None)
    if req is None:
        log('WARNING: none of {} exist, skipping pip!'.format(', '.join(require)))
        return

    cst = find_first_file(constrain)

    pip_arguments = {
        'install': [
            # Perform an install; these flags have to be updated occasionally as pip is updated
            pip_exe, 'install', '--compile', '--progress-bar', 'off', '--pre', '-I', '-r', req, '-c', cst
        ],
        'freeze': [  # Freeze versions in a built venv
            pip_exe, 'freeze', '--no-cache-dir', '-l', '-r', req
        ]  # Preserves comments and order
    }
    assert action in pip_arguments

    if action == 'install':
        env = basic_env(cwd, parallel=parallel, easy_install_proxy=easy_install_proxy)

        # Get special flags from the architecture specific .ini file in the root
        # This is pyboot-$(uname -m)-build.ini, if it exists
        env = merge_build_ini_environment(env)

        try:
            argp = pip_arguments[action]
            if prerelease is True:
                argp.append('--pre')
            subprocess.check_call(argp, env=env)
        except Exception as err:
            log('error invoking pip install {}'.format(err))
            raise
    elif action == 'freeze':
        try:
            byte_output = subprocess.check_output(
                pip_arguments[action], env=basic_env(cwd))
            frozen_fullpath = frozen_requirements_fullpath(req)
            with open(frozen_fullpath, 'wb') as ffd:
                ffd.write(byte_output)
                log('Writing stable, frozen requirements file to {}...'. format(frozen_fullpath))
                log('# ---- END ---- #')
        except subprocess.CalledProcessError as err:
            log('error invoking pip freeze {}'.format(err))
            raise
    else:
        raise RuntimeError('Invalid action')


def frozen_requirements_fullpath(req):
    """Freeze the installed versions of packages in your venv

    This function should be changed or should just go away
    """
    base_requirements_path = join_path(dirname(realpath(req)))
    mkdir_p(base_requirements_path)
    today_yyyymmdd = datetime.today().strftime('%Y-%m-%d.%S')
    frozen_filename = 'frozen-requirements-{}'.format(
        today_yyyymmdd)
    frozen_fullpath = join_path(base_requirements_path, frozen_filename)
    return frozen_fullpath


def main():
    """Let it begin"""
    # This is a relic from when we support 2.6, to bootstrap from scratch on
    # very old (generally commercial) UNIX-based systems. Good memories...
    from optparse import OptionParser
    global DEFAULT_VENV_BASE_PYTHON, PYVERSION

    optparser = OptionParser('usage: %prog [options] <destination>')

    optparser.add_option(
        '--disable-parallel',
        action='store_false',
        default=True,
        dest='parallel',
        help='Attempt parallel builds for native packages')
    optparser.add_option(
        '-p',
        '--python',
        action='store',
        type='string',
        dest='python',
        default=DEFAULT_VENV_BASE_PYTHON,
        help='Specify the full path to python')
    optparser.add_option(
        '-e',
        '--disable-easy-install-proxy',
        action='store_false',
        dest='easy_install_proxy',
        default=True,
        help='Set http(s)_proxy in environment for easy_install to inherit')
    optparser.add_option(
        '--freeze',
        action='store_true',
        dest='freeze',
        default=False,
        help='Freeze versions in a venv for future stability (saves requirements.txt first)'
    )
    optparser.add_option(
        '-d',
        '--destroy',
        action='store_true',
        dest='destroy',
        default=False,
        help='Destroy a venv [default=False]')
    optparser.add_option(
        '-i',
        '--ini',
        action='store',
        dest='inifile',
        default='pip.ini',
        help='The pip.ini file to use from the etc/ directory')
    optparser.add_option(
        '-P',
        '--prerelease',
        action='store_true',
        dest='prerelease',
        default=False,
        help='Use prerelease packages when version is not specified [default=False]')

    (args, venv_dest) = optparser.parse_args()

    if not venv_dest:
        optparser.error('must specify destination')

    cwd = dirname(abspath(__file__))

    ini_load_path = join_path(cwd, 'etc/%s' % args.inifile)
    virtualenv_run_path = join_path(cwd, 'packages/bin/virtualenv')
    interactive_load_path = join_path(cwd, 'etc/interactive')

    try:
        with pushd(venv_dest[0]):
            if args.destroy:
                destroy('requested destroy and recreate', VENV_DIRS, INI_FILES)
                invoke_virtualenv(virtualenv_run_path, args.python,
                                  ini_load_path, interactive_load_path, cwd)
            if args.freeze:
                pip('bin/pip',
                    ini_load_path,
                    PKG_REQUIREMENT_FILEPATHS,
                    PKG_CONSTRAINT_FILEPATHS,
                    cwd,
                    action='freeze')
                exit(0)

            files_exist = [exists(entry) for entry in VENV_DIRS | INI_FILES]
            if not all(files_exist):
                # at least one virtualenv dir missing
                if any(files_exist):
                    destroy('incomplete virtualenv detected', VENV_DIRS,
                            INI_FILES)
                else:
                    log('no virtual env detected')
                invoke_virtualenv(virtualenv_run_path, args.python,
                                  ini_load_path, interactive_load_path, cwd)

            # always try to install the requirements.
            pip('bin/pip3',
                ini_load_path,
                PKG_REQUIREMENT_FILEPATHS,
                PKG_CONSTRAINT_FILEPATHS,
                cwd,
                prerelease=args.prerelease,
                parallel=args.parallel,
                easy_install_proxy=args.easy_install_proxy,
                action='install')

    except RuntimeError as err:
        optparser.error(
            '%s Destination virtualenv directory and Python interpreter must both exist !!'
            % (str(err)))


if __name__ == '__main__':
    main()
